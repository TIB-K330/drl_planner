# drl_planner
Offical code of journal paper titled [*Sample-efficient learning-based dynamic environment navigation with transferring experience from optimization-based planner*](https://doi.org/10.1109/lra.2024.3412610), which has been published on IEEE Robotics and Automation Letter.

## Abstract 

This paper presents a sample-efficient deep reinforcement learning (DRL) based method to address the intricate autonomous navigation task in dynamic constrained environments. The proposed method leverages a graph neural network with feature-wise linear modulation modules to effectively extract features from observations modeled as heterogeneous graph. By transferring offline MPC experience data that can be generated in fully parallel, the training process can be jump-started to cope with the sparse rewards. Simulation results demonstrate a 98\% navigation success rate, surpassing baselines by at least 6\%, while halving the training steps.

The core part of the code has been released, but the training part has not yet been fully organized. If you are interested in this work, please contact me via email.

E-Mail: alexss520@gmail.com
